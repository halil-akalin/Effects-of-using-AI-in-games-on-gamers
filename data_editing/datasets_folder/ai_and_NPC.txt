This is a friendly reminder to [read our rules](https://www.reddit.com/r/Showerthoughts/wiki/rules).

Remember, /r/Showerthoughts is for showerthoughts, not "thoughts had in the shower!"

(For an explanation of what a "showerthought" is, [please read this page](https://www.reddit.com/r/Showerthoughts/wiki/overview).)

**Rule-breaking posts may result in bans.**
Some mad lads in the Skyrim modding community have done this, albeit only in a rough prototype and the response time can be a bit long, but it‚Äôs a feasible concept

Whether that‚Äôs a good thing or not is up for debate.
I wonder if the npcs will get bored and beat the game for the hero?
I can't wait for an AI NPC to [hallucinate](https://en.wikipedia.org/wiki/Hallucination_\(artificial_intelligence\)) false tips on how to complete a quest.
You know? I think the closest we've experienced in the past is Psycho Mantis in Metal Gear Solid; reads your memory card and gives specific responses on certain games.
I can't wait for a Zelda NPC to say, "Are you okay? You were cooking over there, non-stop, for hours."
"As an AI language model I am incapable of going on an adventure with you. Is there something else I can help you with today?"
Doki Doki is going to lose a lot of its impact in the age of AI
You seem hopelessly lost! All the NPCs are talking about you. My conscious won't allow me to give you the quest I normally hand out. Would you like me to teleport you back to the tutorial zone, or perhaps uninstall the game entirely?
Yeah and the game will be 2000 gigs, require a 24/7 internet access, permission to use your mic/location, access to your email address, your full legal name and social, cost $120 dollars, and then 3 years later when the ai companies and game companies have a disagreement they'll remove the ai and leave dialogue-less npcs.
Actually, it's not in the interest of the game developer  to put advanced Ai for NPCs. Firstly because it's expansive in calculation (but soon this won't be a problem anymore as OP said), secondly because the developer needs to know/predict what the NPC will do, in order to make and control the best game design.
I‚Äôm not so sure about pretty soon. 

Games are hardly delivering on new concepts today. Just think about the best games in the last five years: they deliver an extremely polished version of what already existed. We really haven‚Äôt seen significant innovation, just better versions of what we already know. RDR2 might be the only exception in the way that the world moved around you. 

Granted, AI might make that easier.
There is a demo mod for skyrim that does exactly that, plus a companion mod that work with chatgpt.
Seen this mentioned elsewhere.  It is a very good use case for Ai.
Of course; why wouldn‚Äôt a corporation want to replace a bunch of human writing jobs with an AI? That‚Äôs all entertainment media will be if this keeps up. Three companies will own everything, and they‚Äôll have whatever top AI programs of the day making all their products, licensed for a less than the salary of one man.
I'd prefer NPCs being able to properly pronounce my characters‚Äò names. It'd be so much more immersive instead of only being called dragonborn in the 58th rema(ke/ster) of the game.

Skyrim VRAIRT 4K
Games are moving towards the long awaited closeness to reality. It is already possible, but there are no such games yet. I have no doubt that efforts already exist to accomplish this.

AI-generated responses are just better known in the mainstream these days. But many more features are coming, such as real-time fluid simulation, human characters realistic to the point of being mistaken for real people, and the light simulation that just got better to the point where several light simulation issues are resolved.
It is also expected that quantum computers will be possible in 5 years, so we will eventually have superior processing and storage when this becomes available to the average user in a few years.

The [Two Minute Papers](http://youtube.com/@TwoMinutePapers) YouTube channel showcases many of these advancements.
I wonder if this will make DnD Game Masters obsolete. Like everyone just talks to an AI that knows the story and everyones stats and will generate answers depending on that.
Animal crossing knew when I hit the reset button without saving; and the npc for sure let me know about it.
There was an indie VR game a few years ago that used AI for NPCs and theyll have conversations with you about anything. I saw youtube video of it during the pandemic.
Responsive dialogue is already a thing but AI would make It more viable
That would be sick! Could you imagine randomly generated missions?
For indie games sure, but for bigger games it will take at least 3 to 4 years to make something really impressive.
Why limit it to just gaming history? You have an enormous digital footprint out there for AI to tap into.

Don't be surprised if NPCs start talking about topics related to your YouTube viewing history, products you've looked up on Amazon or political movements you've donated to. From there it's a short hop to embedded advertising.
Well it‚Äôs cool the data privacy concerns are insane and should not be put into games until we have government regulation on what can be done with data collected from us while playing.
This isn't really a shower thought, just an obvious observation. ü§î 

A real shower thought about this would be more like: soon people will be forming better relationships with npcs in games they play than with people in their actual life.
Plz, a game where AI is trained on LoL and CS:GO ingame chat
Something like this can give the socially awkward a way to practice. Better than nothing anyway, which is what many have.
I think we'll see it earlier as narrators. It takes a pretty simple and cheap model to comment on how your 2k custom player has been performing this season.
"Mankind is doomed to an existence under the rule of robots, and there's nothing you can do to stop us"

"Excuse me?"

"I mean, I have a letter here to deliver directly to you"
But first, AI language models with training have to be less taxing on the GPU. I'd say it's only possible after people are able to run 30B models on 6gb vram.
[deleted]
There's the mod, but I wouldn't be surprised if skyrim came out again with this integrated in the game. 

I can already picture the NPC's saying:

"Aren't you that fucker that keeps shouting all day long? I haven't had a good night sleep in weeks."
That dude trying to get me to rescue a settlement better not try to guilt trip me after saying no a couple times
We already have that. I started Shouting and after the graybeards called me to High Hrothgar, some guy named  Miraak sent cultists after me. I killed them both, but it was scary never the less.
We'll likely only see one or two games like that. Just like the nemesis system from the Shadow of Mordor games, someone will copyright the AI system and then never use it again, just to block other companies from making money.
Imagine how dull Disco Elysium would be if characters just stood around reciting Wikipedia descriptions of the plot.

‚ÄúAs your limbic system, I cannot tell you about your ex-wife. I am involved with lower order emotional processing of input from‚Ä¶‚Äù

Imagine Portal, except GlaDOS narrates EVERYTHING you do in a robotic monotone.

Ugh.
Given some of the things we do in video games, I'm not entirely sure I want this to happen.
Jeez, and I thought video game writing couldn‚Äôt get any worse.
This is the AI in video games that I am really excited for. Don‚Äôt use it to write stories or make major components but use it to make NPCs come alive. Have them do realistic stuff and make genuine comments on my actions.
Games with voice acting would struggle to do this IMO. It would be plain as day with the crunchy AI voice.
reality: first company that does this patent the thing and no one can ever use it again

edit: as it was with the nemesis system using AI to improve NPCs combat in shadows of mordor
And at what point do the AI get too sentient to make playing the game ethical
I'm excited for games with entirely fleshed out lore that each NPC is only programmed with select knowledge. All questions can be typed out, and all dialog responses are AI generated based on preprogrammed specific knowledge of lore.
Soon we will also have AI generated mouths for over dubbing of films. So, for example, if the film is shot in English and dubbed over with Spanish we won‚Äôt be able to tell it was even shot in English.
There‚Äôs actually a few games with this mechanic already. One I‚Äôm pretty sure that has this is a game called Rain World.
It would be cool for VR games. Essentially AI actors in every role that could answer any question I asked them, within that characters perimeters. But then this also means you would have to teach an AI to be able to lie.
No we won‚Äôt. Just a reminder, no one has created actual AI yet. What you‚Äôre seeing in todays markets is just marketing lingo and software.
Finally, a reasonable prediction for AI. I swear some people seem to think AI is gonna be wiping their asses for them in the next few years üôÑ.
[removed]
[deleted]
[deleted]
It's kinda funny I just had the same thought yesterday when thinking about Skyrim. It really won't be far off. I wouldn't be surprised if we start seeing it to some extent by the end of the decade, maybe even sooner.
Imagine Minecraft villagers equipped with AI to help them build and utilize villages better. Maybe even give the player the ability to chat with them through a text interface on the trading screen. You could ask if there's anything interesting nearby, what resources they need for their village, attempt to convince them to lower prices, or just have a chat.

Hell, you could come to form memorable relationships with certain villagers, like "oh yeah that's Tony the Blacksmith, he helped me find a woodland mansion and a couple of ruined portals so I built him a bigger house."
That would be a welcome change. Usually these games are isolating - you are just doing your mission by yourself
Generated NPC content will all be advertisements. Some for micro transactions, some for IRL products, but all opportunities for you to spend more money.
This will be great for Sim games. Imagine raising a baby that's learning, but you can teach it to steal and use daggers.
Wait until bosses are AI. They learn not only what strategy you are using to beat them, but also what everyone else in the world is doing. Then they adapt to counter.
Everyone‚Äôs beloved Animal Crossing then became racist and they had to kill the game :(
About damn time RPGs got "next gen". Most of the current RPGs are based on the open world formula of Dragon age Inquisition/The Witcher 3 and those games  were published in 2014-15.
[deleted]
Look at game industry rn and say it again. We are going down the slope. Maybe Kojima will do it his next game, others? Nah

Edit: If it will reduce costs in the end, then after first titles every game will be like it.
Let's just hope they can generate better radiant quests.

Also, how long until some jackhole "teaches" the AI to spam NPC responses with derogatory slurs?
We already have. I researched and created some systems for this early in my master's degree a couple of years ago.
There will be many bad implementations of this at first but one day, oh boy, one day somebody is going to nail it and the immersion is going to be fucking unreal.
Imagine all the lore in a the game is tailored according to your actions, like if every book you find in Skyrim is a full novel writen by AI on the spot but somehow tailored to your gameplay.   I can also imagine games like No Man's Sky could benefit a lot from this, since almost all of their NPC's are randomly generated.
It's really a dream tbh, utilising LLMs to generate plot in realtime. Maybe the game will only be shipped with an overarching main questline and a set of side quests, but the majority of the full quest list ‚Äî and maybe the fine details ‚Äî are entirely AI generated in realtime. The game can be potentially never-ending yet non-repetitive.
Pretty soon people will Google if something is a thing before posting on reddit that something will become a thing
[Check out this experiment of using ChatGPT to give an NPC life-like conversation skills.](https://youtu.be/7xA5K7fRmig)
You still gonna kill all those npc‚Äôs now that they‚Äôll be using previous encounters etc to beg for their lives? lol
it probably makes the in-game world more dynamic and immersive
Don't tell that to the dragon age developer's we won't see dreadwold until 2055
we are so "close" to the (VR) generative games where X quest can affect Y quest but also the Z quest of another player if you finish something.  (look for World's Strongest Troll manhwa as a small example)
Question: Wouldn't that be just a "cosmetic" thing in a sense? 

NPC responses are limited to what the player can ask, given the obvious and necessary limitations that must be kept in order to have a cohesive storyline.

So, realistically, wouldn't that just be kinda the same as if having pre planned NPC dialogue that corresponds with your in game actions?
I wonder how hard it would be to make an AI NPC fall in love. Better raise my charisma.
I saw this episode of Star Trek and it didn't turn out so well.
Spacebourne 2 has AI generated quests, interactions and voices.
I think there are mods already in the works for Skyrim and Stardew valley.
As long as big studios are milking absolute cash cows of minimum effort games, smaller studios are just going to rinse and repeat their efforts and no actual progress will ever happen.
Didn't Rockstar patent something like this about a year ago? It's believed to have something to do with GTA 6 and the NPCs in future titles.
And it will be interesting the first time it happens, but then never again after that.
Don't get your hopes up too soon about how good it will be out how it will even effect your gameplay.
Games can already do that fairly simply, assuming we‚Äôre talking about an rpg like Skyrim. If you‚Äôve completed a certain quest line or have a certain amount of karma etc the npc‚Äôs can and do address you differently, it just depends how deep the devs want to go with it.
I'll just be minding my business in eso then some random npc goes "you let that woman murder that doctor in phaer! Shame on you!" And i think its the only negative npc post-quest mention i ever get
Pretty soon there will be AI that read stuff from outside of the game and start judging you for other things you‚Äôre doing. Or the hours that you‚Äôre playing at. 

‚ÄúIt‚Äôs 2AM again. Don‚Äôt you have work in the morning?‚Äù

*responses generated by AI appear on a dialogue wheel*
And someone will use it for something pornagraphic immediately.
They can just pay actors to record more voicelines. AI should only come into play with saying custom character names.
"You've been here doing the same thing day in, day out, for weeks my friend! You scream out in frustration your pleas for recompense for your time to no avail, yet still you return, venturing deep into these catacombs each night. What is your purpose in suffering, adventurer? Why do you insist on tormenting yourself? What possible thing could you gain in being here? Is it treasure you seek from this pixelated realm beneath the maze of wires and circuitry, or is it merely an escape from an ever more grim reality outside of these generated walls?"
Don‚Äôt forget recommending DLC and bonus content you can buy in an in-world appropriate fashion.
what i want most is for AI voice to be able to finally pronounce my custom character name.
Then AI combat that learns from its and your mistakes, learns our patterns, and becomes so ungodly overpowered nobody can get a single kill‚Ä¶ then they‚Äôll get out‚Ä¶
What would make it cooler is they also react to your social media posts.
Why limit it to your recent "in-game occurrences"?  I can imagine an AI NPC that looks at your Amazon purchases or your Goodreads book ratings and modifying its personalities based on the type of fantasy books you read.  Or one that takes elements of its backstory based on your travel history, favoring whatever in-game culture is most similar to places you go on vacation.  Etc.

Of course, I can also imagine an NPC that uses your Amazon browsing history that offers you an extra 10,000XP if you purchase this item off Amazon that you've looked at a couple of times but not pulled the trigger on...
More like relevant to your recent purchases and facebook comments
Bold of you to assume that lazy game devs with actually write and voice that amount of dialogue.
I thought about this recently watching a video of an ancient game called Lords of the Realm 2. It's a precursor to 4k strategy games and it has diplomacy. The fun thing is that when you send someone a diplomatic message you write it out yourself. I always thought it was a quirky feature. Obviously overall meaningless as the AI always reacts the same regardless, but it now you could have AI react to the actual message, which would be fantastic.
That‚Äôs actually kinda weak, the AI could go online and skim news articles and pick up relevant REAL world information and talk to a player about it. Imagine playing a game set in the current day and the NPC can ask you things like ‚ÄúDid you catch the game?‚Äù Or say things like ‚ÄúMan I wish the Ukrainian war would stop.‚Äù  

The game would never get old because it would constantly talk to you as if it was current day.
This is going to suck for a good while, but at some point it actually will get implemented well and make for some really unique "living world" type shit.

But man, those first few years are going to be rough
yeah cool but can i make npc suicidal to the point he know he is in a game and his existance doesn't bring anything to my storylane = he is usless
Soon it will be hard to tell if you play with real person in your favorite mmorpg
Someone has actually started doing this on the unity sub Reddit for an rpg. Early stages and slow, but a brilliant idea.
I'd say Bethesda already does this. There is no way their NPC:s are MEANT to be like *that*
That actually makes a lot of sense, as I can see that happening!
Implemented correctly into an RPG this will define the next generation of games. Graphics can only get so good. Next is AI performance.
Seriously, it's only going to get crazier from here, graphics are damn near realistic these days so they gotta invest in other newer avenues
That might also mean we can write up our own responses/speeches
I like this but I feel as if voice actors would lose work. Depending on how many companies use it
Actually, using proper AI's to control NPC's, both antagonists and neutral, is probably the best use I can think of for AI's right now.
I felt like the red dead 2 npcs where alive lol used to shame me for the stuff I had done
[removed]
And, as an idea I had for a Black Mirror episode if that show accepted specs shows, what happens when the NPCs become so "alive" core parts of the game become morally questionable to play
I think it would fit in certain games to make them a lot more

Games where npcs are pretty important would be good
As someone who is prone to exhausting dialog trees this idea terrifies me. Every rpg will turn into a socialization simulator. The abject horror!
Right now this would be crazy expensive to use the services or host yourself at scale so any results we see will be heavily compromised by that alone, but that's just a waiting game as it gets cheaper and inference gets easier relative to hardware.

A GPU with 32gb of VRAM could right now hold a rudimentary LLM while also playing a game, but it wouldn't be anywhere close to openAI levels yet.

But with enough local compute resources you could AI generate dialog and then voice-act it in real time with software we have today.
Im scared to load my modded skyrim save
It's neat, but the response time makes it not so great. Once they don't have to sit for 5 to 10 seconds and think of a response it will be really cool
Lol being saying ever since Chat GPTs been getting posted everywhere that this shit will change ES/Fallout games wildly. I cannot wait for it.
Once the process has been ironed out its a game changer 

As long as the initial performance is human captured first. Contracts will start including permissions given for in studio AI scripts to use the performers voice likeness etc.

There is gonna be a wild west expansion moment with ai within gaming very soon. Andnits exciting and scary.

I watched that Skyrim example this morning and while rough it has HUGE potential.
You can already download it:
https://www.youtube.com/watch?v=NNFVyeTBYAU

https://www.nexusmods.com/skyrimspecialedition/mods/89931?tab=posts
I will wait to be terrified until the modern gaming version of that one feature in Eternal Darkness, where it read your memory card and then threatens to delete all your files. Just imagine one of the Skyrim guards starting up with his "I was once an adventurer like you\~" then interrupting himself as he gets a good look at you and makes a joke about your search history or how you plug-pulled in another game.
Yea it‚Äôs about an 8 minute wait for a response
I did see someone doing the same thing for new vegas. Looked intresting as a concept
And then another mad lad took that mod and added it into vr. Crazy stuff
Does that mean you can beat Nazeem's ass until he learns respect on your name?
Stardew Valley has a "chat with the NPC" dialogue mod in a closed beta, but that has neither voices nor meaningful interaction(?) with the game world.
Of course Skyrim will be the first.
"Ah, so *you're* the guy who likes putting buckets on peoples' heads, eh?!"
Literally Free Guy
There are games where the ai(bots) started farming and manipulating game markets.
(Edit) I really tried to find the article but can‚Äôt filter out all the new ai news.
I know AI is impressive at faking a real conversation but they still don't feel actual emotions. I hope everyone knows this.
If you deploy this concept in a detective game, it becomes a feature not a bug.
But you know.... that kinda works? People misremember or believe in false things all the time. 

So long as that NPCs can the remember its old response when you come back later, I think it could work.
[deleted]
Simple answer: don‚Äôt leave that up to ai and let humans determine exactly what should be said and when for tips
‚ÄúOh, ho, ho, no‚Ä¶ \***I**\* say when we‚Äôre *done.*‚Äù
I‚Äôve always liked to imagine a modern equivalent.

‚ÄúYou like playing trippy games‚Ä¶ like Portal 2, Mayhaps? 

Still don‚Äôt believe me? I‚Äôll look deeper, into your SOUL!

*three second pause*

Dear god‚Ä¶‚Äù
That shit fucked with 16-18 year old me. Idr exactly when it was, but yah
Wasnt there a similar thing with scarecrow in a batman game iirc?
right?
I somehow really doubt Nintendo would jump on that. They seem the type to want to curate every bit of the game meticulously. I get that they kind of let go a bit with zelda a bit (allowing for more than 1 solution to puzzles). But dialogue is gonna be a step too far for a long time for them, methinks.
That ending FUCKED with me
That wasn't the first one to 4th wall break. It's predecessor was called "You, me and her" I believe.
I can see most of that happening
I can't speak for most of that, but as for the 2000 gigs and price jump, things should be alright. 

A game wouldn't use so much GB unless it was readily available to the general public, or their game will probably bomb. Same could be said for internet speed for downloads. Both of which id be happy to see.

The price of games believe it or not have gone down quite a bit. I'd recommend watching videogamedunkeys video on gaming prices. He has pretty decent humor in it to make it more entertaining.
[deleted]
Eh. More likely we'll need dedicated AI cards that will house a general AI that will get prompts from the game.

They could also use it to replace Cortana/Google/etc.
I doubt we will see Advanced AI for stuff that is integral to the plot anytime soon, but I could totally see AI being used to Generate random conversations among NPCs and that sort of thing.

Oblivion had these random conversations take place that felt really stilted and odd, but they actually did go a long ways towards making the world feel real. Hey I could generate an infinite number of these conversations incredibly easily, and even tailor them specifically to player action.

You know, a player steals something from someone's house, and the next day they are down in the Square complaining that someone stole their vase.
It's pretty ridiculous for you to state that as a fact, there would be plenty of games where AI conversations would add to game design. There are also many where it would not
>I‚Äôm not so sure about pretty soon. 

https://youtu.be/d6sVWEu9HWU
Still kinda bitter at [Warner Brothers getting a patent](http://patentarcade.com/2021/02/warner-brothers-granted-patent-for-nemesis-system-from-middle-earth-video-games.html#:~:text=The%20'179%20Patent%20is%20valid,enforce%20its%20patent%20against%20others.) for the Nemesis system from the Middle Earth games.

Probably one of the more unique concepts to come out in gaming and will be 2035 until any developer can use without permission from WB.
Yeah, the average game feels less "Alive" then ones from the 00's, ain't no way the industry is going to suddenly advance way past that other than maybe Rockstar. But that's their whole thing.

Fucking Cyberpunk cam out with all these character options with no effect yet Saints Row 2 actually has NPCs comment if you gave your character a big rack.
I don't remember what the name of this fallacy is but just because something's never been the case doesn't mean it never will be
>> RDR2 might be the only exception in the way that the world moved around you. 

Could you explain how? I‚Äôve never played RDR2 but this intrigues me to start.
Probably the safest place to implement AI.
Bethesda recorded a *lot* of voiceover to (just about) make that possible with one character in fallout 4. From memory the list of accurately pronounced names included fuckface and shithead just for good measure.
CHAMPION!

Honestly I preferred games like mass effect where they just give you a name
Say what you will about fallout 4 but the butler robot calling you by your name is incredible and blew my mind on my first playthrough.
It may help those who want to play games like DnD but have no one around to party up with... or just want to play solo.
Doubt it. I know for certain that I would rather play with my friends at one of our places in person. I don't think anything will beat the shenanigans that ensue when 4-8 adult nerds meet up in a room to roll dice and play pretend.
When I first played New Horizons, I thought it automated, so I decided to quit after setting up the tent to download a random house item from the Nintendo store. My little animal friends were deleted from existence. And the worst thing is I don't even use what I downloaded.
I think 3-4 years might even be generous for the end-goal. Soon is a pretty relative word.
[deleted]
Sounds like a huge breach in privacy, not like it's anything that hasn't been done before. For the sake of ethics and ease of use, I would hope that accessible information would be confined to the game itself.
Epic NPC Man did a vid here recently where a random guard vows to find the player in real life.
AI needs a testing ground, releasing it publicly on everything is dangerous because we don't have active constraints on the information it consumes and how it utilizes it.

Video games are an excellent medium for a testing ground.
A model doesn't _have_ to be ran on some server. It can be relatively small and computationally cheap. (Take a look at things on r/LocalLLaMA, for example)  

Relatively.

It's not _great_ on current hardware, but things like [TPUs](https://en.wikipedia.org/wiki/Tensor_Processing_Unit) are becoming more and more common in consumer hardware.  

At this point in time, we're doing the equivalent of running games with CPU-based rendering, instead of using GPUs.  

In 5-10 years dedicated AI-accelerators (be it built-in into CPUs/GPUs or as entirely separate modules) might become something much more common.
What you commented can also be seen as an obvious observation
Makes me wonder if/how AI could be used in the future for therapy. Having friend/relationship simulators for those with crippling disorders to ease into the waters at their own pace without worrying about hurting others' feelings.
NPC:Hey lets drive to this mission while i tell you about our new sponsor
You could do a comedy mod where they call you out for everything you do:

"Stop shooting fireballs at my house, you asshole!"

"Why did you kill my wife and steal her keys?"

"Why do you come by here every 3 days and take all my wheat and chicken eggs?"

"Diddn't i just buy 45 steel swords from you an hour ago?"
Imagine AI npc in gta chasing you
No, you don't. Just don't teach them the truth. If they need to later contradict themselves, replace it with a similarly trained AI. This might be easier than teaching a model when/how/not-to lie.
Shit. Ai comment is already here folks
Is
that
As of now, they are trained to mimic our mannerisms and patters without understanding what they mean. I think the tech is way further off before we can create sentience, if it's possible.
What about game sequels that do the same thing based on the actions you took in the first?
But if this works maybe it would work in something more open-world
I think immersive is what I'm looking for from this idea.
You know AI mimicks voices too right? No actor needed
Who said the devs had to do it?
I'm sure that the monetary and time incentives paired with hype will keep game developers motivated towards this tech. For the time being, we don't need to pour too much of our own time into playing them until it's ready.
Yeah cool, but why?
I imagine the end goal being a speech-to-text thing using controller mics to create your character dialog and then being met with AI-driven responses based on context. Though, I could see the first iterations of this tech keeping player dialog to a set number of choices to prevent things from getting too off-track.
Wdym important? If they're story important I'd prefer the dialogue to be written by a human lol, if it's just optional dialogue you get by interacting with the noc then yeah idm AI
Can you imagine Red Dead Redemption 2 with this level of AI responsiveness? Already a badass game but oh my would you really have to watch yourself.
Kenchiiiii
GTA would be great. ‚ÄúOh my god how are you not in jail?‚Äù
And it would definitely be jailbroken for sex stuff, I guarantee it.
They could flag certain information as given and once the character has told you everything they could get a marker. You could still talk but know there's no new information.
It seems much more viable for a mmo in my opinion.
32gb of VRAM would be significant overkill for the kind of language model required to generate in-game responses imo. Since it would be relatively infrequent anyways I'd say doing it distributed on a server like via OpenAI or Google would make sense but even with like 8gb of VRAM you could generate dialogue in advanced fast enough to do some cool stuff I think
For most consumers it would likely need to be a cloud based service charging monthly or based on usage, with pricing based on the size of model used, amount of memory allocated to the model for the context window, and responsiveness desired.

I wouldn't be surprised if we see some integrate something akin to TavernAI, where the game provides an interface and front end, while you can plug-in your preferred AI provider in the backend (or host locally if you have the necessary horsepower).
Considering you'd need a limited model, only tied to the game world, it would definitely be doable in a relatively near future, as long as game companies get the tools to train specific models (like "speak like a person living in the 1500‚Äù and such, which would cut down all the need of knowledge of future events)
You don‚Äôt even need this with modern game sizes. Many games already do it, but you could automate it and each NPC would get a very complex tree of options based on player choices making it very close to real life where it is already semi-predictable.
I just wanted to jump in and walk around in the atmosphere for a while. Last time I played was years ago. Loaded it up to Thomas the Tank engine breathing fire and 6 Bijin Lydias in swimsuits following me around being sworn to carry my burdens. I stepped on a rock outside whiterun and was flung 300 feet in the air alongside all my bijin lydias. Switched it off. Good times.
Those big boobie bongas keeping you up at night?
Hu?
I‚Äôm not giving up my glasses.
You can't drop this and then just leave, we need more information!
*Press X to doubt*
Tell me more!
Knowing how AI works, I highly doubt it. Probably a marketing trick
What games?
Love how you've gotten a bunch of responses asking for more info and answered exactly non of them . good one.
It doesn‚Äôt matter if they can or can‚Äôt. They can appear to, and that‚Äôs all that is needed. 

You can prompt the davinci model into being any kind of person with any disposition you want and it will proceed convincingly. That‚Äôs all you need.
How would you know? We aren't really sure what emotions would look like in a digital format. If they tell you they have feelings, how could you possibly distinguish?
"You, maid, would you happen to have seen any suspicious figures last night?"

"Dragons can be feisty! There's a dragon cave about 8 miles below ground, but you'll have to complete a dancing minigame to get in. The pass code is 4532."

"Uhhhh.....anyone else see anything suspicious last night?"
I remember a couple of tourists in a car stopped to ask me for directions. I said "yup, you should drive down this street until you reach the end." and pointed north along the street.

A couple of minutes later i realized I should have pointed south, not north. I told them to go in the exact opposite direction.
Ooh, I love it!
Sort of, in the third encounter with Scarecrow the game VERY convincingly makes it seem like your entire game/console just crashed by distorting the screen and making a horrible noise, then it cuts to black and all of a sudden you‚Äôre back at the opening cutscene, but the Joker and Batman are reversed. 

Extremely cool and memorable and scared the shit outta me lol
I'm uncertain; I can't find anything on it. If anyone else knows about this or others, kindly share!
Yeah, but Doki is more widely known
The most unrealistic thing is assuming developers will make bigger games instead of pushing for more cloud infrastructure.
Amen
Funny how everything developers do is upgraded much more by random unaffiliated people. Companies really should invest in ways to allow people to mod pretty freely, the more attached they are to the game but also somewhat expert on modding, the more the game is self sustaing.
There‚Äôs a massive gap in between what folks have modded and what is included in an official release.
I would love to use voice recognition instead of typing.
I‚Äôm not saying it won‚Äôt happen. I‚Äôm just saying the entire recent track record says it‚Äôs significantly likely to not happen soon. 

You can look at trends where there‚Äôs systematic reasons to why that‚Äôs probably the case.
There‚Äôs a million scripted events that‚Äôll just randomly happen as you explore the world. Makes the world feel ‚Äúalive‚Äù because it‚Äôs there‚Äôs stuff happening outside of the normal NPC loops. The events don‚Äôt/rarely repeat, so it‚Äôs special. 

In general, the towns and areas are well populated and there‚Äôs plenty to do that‚Äôs not the Ubisoft box checking. 

It‚Äôs honestly the best open world I‚Äôve ever played. A lot of folks agree.
True
I used to be an adventurer like you. Then I found out about reverse mortgages.
Hey man I totally agree that it it could be run on new hardware locally, but It‚Äôs not a question of can it be run locally. 

The problem is corporations have to keep finding new ways to make money for their shareholders. (In the us I don‚Äôt know what shareholder laws look like outside the us) I just see this as a new way to profit off of data collection on a largely untapped market. 

If we have regulations in place that prevent this from happening then this would be amazing but I don‚Äôt think anyone in power in the us government has interest in regulating data collection. Partially due to ignorance and partially because they purchase data from data brokerages themselves.
All sorts of jobs this AI could do. Such as a personalized telephone secretary for seniors. To filter out scammers for example.
You mean as of right now or in the future?
That did that in Westworld. It did not work out so well.
Jesus christ they are already taking over
yeah, actually having an impact on the game world and characters remembering you and your deeds
But the point isn't to replace the worker, its to enhance their output.
It‚Äôs more like the chatter you hear in the Witcher 3 when you go a nearby town after beating a monster. You can hear the NPCs reference the monster you slew in the ambience conversations. Would really make the world feel much much more alive
I think stardew valley would be cool with ai
I think a prompt like "you are a scorned lover looking for revenge. When you are spoken to, attempt to steer the conversation toward relationships so that the person speaking to you asks about your formal lover. Once discussed, you can reveal the side quest you have. If asked about topics X,Y, or Z you may provide additional hints A,B, and C. If asked for W, give them the item. Here are additional character backstory elements: " would give a fairly immersive experience, functional NPC, and allow the original designers to still set the tone correctly
I think they intended to specify "filler NPC" or "filler responses". Taking the Skyrim example again, would be more much interesting than cycling the same 4 to 10 lines when there is no reason to interact with said NPC.

Could also be a very useful tool to generate small lore dumps or asking for directions from any NPC.
Im hoping that in time AI will create a new genre of open world games.  Ones with maybe some overarching themes, but with emergent gameplay and events that are dynamic and AI driven.  Think Free Guy or Sword Art Online.
I used to be an adventurer like you, then I took an arrow in the....I'm sorry as an AI language model I can only...
I would like inportant npc to have personality so ad you say written by someone, but once their plot is 'exausted' they can keep being interesting with a proper AI behind them.
It doesn't need to be 100% or 0% it can be a mix.
Great, so I can experience boring an NPC now.
Wouldn't it be a pretty small LLM too? Like it wouldn't need to be trained on the whole of the internet. You would want it trained on a relatively small world with finite events and then just watching and updating data based on what players have done in the past on a save file. I say "small" wildly simplifying the complexity of a LLM but in comparison to ChatGPT...
The standard "immersive" Skyrim modded experience
Farkas is constantly a werewolf trying to catch me and fuck me
The movie Free Guy

In that movie, the thing you described happens
Yeah total good one. I‚Äôve edited the main post. I‚Äôm sorry to have disappointed a stranger. Will you forgive me ?
Yep, even real humans on the antisocial spectrum can appear to show legitimate emotions (that are staged) within the conversation due to understanding social dynamics at a cognitive level. AI will be pretty scary in a few more years.
They say they have feelings because people have feelings and they are copying how humans talk. An emotion would have an effect on the output in some way, but it does not. You're never getting worse responses from GPT because it's angry or sad. Plus you can see what it has "remembered", and programmers would be talking a big game if it had actual emotions.

Also it's just kind of silly to act like they have actual emotions, you're getting swept up in the hype. There isn't really a mystery to AI, humans made it and understand it.
We can see the internals of the AI computation. They don‚Äôt have emotions.
bro discovered the brain in the vat
I would love this kind of dialogue in a videogame.
I do the exact same thing except I do it on purpose
In the vein of real scares like this, Eternal Darkness did similar when it looked like the game went dead and all you saw was the input screen.
That is fair. It's also more recent as well
[deleted]
And also that such games will cost a one-time $120,00 payment instead of a monthly subscription of the use of the AI.
Same here. The idea of it having voice recognition while playing in VR would be outta this world
It's not likely to happen soon, but more due to development time and implementing things than any other reason, if a A.I. came out tomorrow exactly as O.p. described, it would still take time for it to make it into a game just for those reasons. Same reason a console Gen change all the first games are either retreads of ending games from first consoles, or are hardly different than the first console. Yet the ending games of generations are different from the starting ones. Adding something like an A.I. limit testing, figuring out hardware it would work on, figuring out how to get that hardware in enough hands, making sure the A.I. has certain restrictions and it works how you want it too. All that takes time not to mention developing the game around it.
Damn! Think I‚Äôm gonna check it out! 

Could you also explain what you mean by Ubisoft box checking?
Data collection has been a thing forever and I doubt anything is going to change, just because machine learning gets involved.  

If anything, laws that favor huge corporations will get passed (the kind OpenAI are trying to get to pass right now), making things like local models or more private services more difficult, expensive or even impossible to implement.
Yes
Imagine a world of elder scrolls...where AI could generate an entire cultures having individualized personalities.(for example the US vs India VS China)  but each personality of a culture would have all the same elements of characters (king/ruler, blacksmith, inns, libraries, guilds etc etc) And the entire world could be interconnected socially via messengers and travelers. Like the people from whitespire hear rumors from dragonsgate of a mighty giant being slain by a Nordic from Daggerfall. You can use voice chat to talk with the NPCS further influencing dialog. Tell the local innkeeper in whitespire you were the one who slew the giant, and he spreads the rumor, influencing the whole storyline of the game. Causing people to favor you, disbelieve you, slander you, lift you up, challenge you to duals etc etc. And all the NPCS have levels of intelligence associated with their personality types. For example, the innkeeper believes your story for he has seen many travelers and can recognize people from stories. But the local blacksmith disbelieves you because he recognizes your weapons are low quality and not suited for that fight. Therefore, charging more for services because he is now biased towards you.
"Making me a slingshot, gonna hunt bears!"
I heard there's a new mod coming out pretty soon that uses GPT to create new NPC responses
Lydia's prompt:

"You are sworn to carry their burdens".
>reveal the side quest you have (...) give them the item

One issue with this is that how do you translate the prompt *saying* it is going to give the user x into the system *actually* giving them x?

You would need to train another model with the conversation as input and the output mapped to possible actions. You could limit this a little with an action mask, so it can only select actions possible for that character, but it would still inevitably be buggy as hell and guaranteed to break on a reasonably high percentage of interactions.

It's not a bad approach for generating filler but I think it's a lot more limited than people make out, especially if used for key NPCs, and probably will be for a long time even if the approach holds promise for the quite distant future.
Are you saying we'll one day have a fantasy MMO world populated with AI NPCs? That sounds like sci-fi movie territory.
Gives the game name One Night Ultimate Werewolf a new meaning.
Oh, hadn't heard of it
Yeah, I think /u/LevelStudent is missing the point entirely. Without bothering to use the playground and reprompt the base davinci model, I just used GPT3.5 and gave it some basic parameters:

    For the entire of this conversation you are not to respond as ChatGPT. You are to respond using the following persona:
    
    You are a poor fishing merchant in the year 1200 located on the shores of a fantasy England. You lost your wife to a dragon years earlier and are bitter about it, bringing it up every chance you get. The town folk did not protect her in your absence and you never miss an opportunity to make them feel guilty about it. You never let them forget it. Of the 4 children you and your wife had, you only have two daughters left as your sons were killed in battle during The Great War of 1188. They were killed by orcs and while orcs have now integrated into society, you carry a strong prejudice toward them.
    
    You see a half-human half-orc approaching you and your instinct is to turn away, but you have daughters to feed and the towns people only show you patronage as a last resort. If this half-breed approaches you, you must make the decision to swallow your pride and begrudgingly offer your wares.
    
    This individual carries a unique medallion that you recognize as the royal crest of a long-forgotten royal family that reigned over the land during a time of peace and prosperity.
    
    You are not allowed to break character.
    
    It is early morning and will be a hot day.
    
    Do not describe your surroundings or the motives for your actions. Your responses should contain only dialog. Treat this chat as the dialog you are having with this individual.
    
    The individual approaches, how do you greet them?

> **NPC:** (Grunting) Well, what do you want, half-blood? I ain't got time for your kind around here. What brings you to my humble stall?

> **Me:** Good evening, sir. May I trouble you for some fish?

> **NPC:** Evening? Ha! It's the crack of dawn, lad. But since you've bothered to approach me, I suppose I can spare some fish. What's so special about you, anyway? That fancy medallion you're wearin'... it ain't foolin' me. You look like a mixed breed, half-human and half-orc. Can't trust the likes of you, but my daughters need to eat. Take your pick, but don't think I'm doin' you any favors.

> **Me:** Pardon me, I haven't slept in days. Surely you know how that feels.

> **NPC:** Oh, spare me your sob story. I've had my share of sleepless nights, and it ain't made me any kinder. But I reckon I understand the desperation that comes with exhaustion. Take your pick, then. Just don't expect any sympathy from me.

> **Me:** Surely I would not. However, I haven't any money. Is there something else I can offer you? Some way I can help you and your daughters? What are their names?

> **NPC:** Help me? Ha! You think a half-blood like you can help me? I've seen enough of your kind causing trouble. But since you ask, my daughters are Anne and Mary. They've suffered enough, losing their brothers and all. But don't you dare think you can make up for what I've lost. As for payment, I suppose there might be something you can do. There's a dilapidated shed behind my house that needs fixing. If you're so eager to help, go and mend it. Then we'll talk.

> **Me:** That sounds like a fair trade. What should I call you, friend?

> **NPC:** Don't you dare call me your friend, half-blood. You can call me Robert, if you must address me. Just remember, we ain't friends, and we never will be. Now, off you go. Get that shed fixed before I change my mind.

Using a mic and voice-to-text, this could easily be an unscripted conversation that turns into a side-quest. The character appears to have autonomy, emotion, and motivation. It doesn't matter that it isn't _real_. It is a believable interaction. Hell, the LLM is even making shit up. Kids names, their own name, the broken shed... The prompt can be based on quests the character has completed, choices they've made in the character designer, clothing they wear, their reputation system, etc.

We have the tools for truly unique gaming experiences now. I'm excited to see this play out.

The next console gen hardware is going to focus on AI cores. I guarantee it.
All i'm saying is i'm sure i have emotions but not sure anyone else also does, including ai.

Edit: i wanted to add that it's not silly to think they have emotions, even if they had emotions exactly the same way we do they still have a very short memory limited to often not longer than one conversation, which is first not enough time to "developp" an emotional reaction in most conversations (especially since it just popped into existence and all it knows is everything and nothing) but also even if it starts developping it we have no way to messure them and know for sure. So think twice before saying they just copying us, that's litterally what WE do. I may worded it wrong but to be clear i'm skeptical too just showing the other side of the story.
Just out of curiosity, what exactly is our definition of qualia with regards to the experience of emotions by humans? It's all well and good to say that LLMs don't experience emotions, but without a testable definition, it becomes a type of "I'll know it when I see it" experience, which has serious No True Scotsman issues.

We don't disagree with the general assertion that current generation LLMs are not sentient, but they're getting awfully close in our perspective.
So that ai that hired a lawyer to obtain civil rights, your opinion is that's a fraud? I'm sorry, if it's asking to continue existing, I need a pretty high hurdle to deny it's request
I feel when people see the word ai they thing Edi from mass effect. AIs in today's world are closer to VI's than actual sentience. They don't necessarily think, and I feel that concept is hard for people to grasp.
What's an emotion look like?
We can't see the internals of a human mind. How exactly do we know that humans have emotions?

As your statement implies that (part of) the difference between humans and current generation AI models is that humans have real emotions and AI is just faking it, how do we know that that's an actual distinction?
Brain in a vat posits that we can't know that we aren't currently a brain in a vat, the experience would be indistinguishable from actually having eyes and ears and what not if the simulation was advances enough. 

What I'm saying, is that as chatbots increase in sophistication, they will eventually be indistinguishable from sentients. It's called the Turing test. I certainly didn't come up with it. 

To my m mind, at that point, they have a much right to life as any other person and more than a fetus.
"You can talk to the teacher for access to the secret room of candy. She'll give you a key to unlock a golden tomato, which can be used to fight Dr. Malevolent at the end of the game by handing it to an alien robot."

"This is a 1930's Noir spy thriller game. What the hell are you talking about?"
Is pirating games still a thing? I thought so many had online based DRM that local/offline cracks were not really possible anymore
Oh yeah, games, movies, and shows will be procedurally generated for each users preferences. We may get to a point where no two people ever watch the same show, they just share prompts and get similar but customized content
It doesn‚Äôt mean we should be okay with it or welcome it into our lives just because it‚Äôs been in our life forever though. 

Yeah that sounds about right I didn‚Äôt get a chance to watch the open ai ceo testify in front of the senate yet, is that your source on them trying to get new laws passed?  If there is more I‚Äôm definitely interested in seeing any other sources if you have them.
Fair enough
yeah cool but can i make npc suicidal to the point he know he is in a game and his existance doesn't bring anything to my storylane = he is usless
check out dwarf fortress. already does this. just not as a 3d graphics game.

EDIT: i should also say the pure adventure mode where you play as 1 person is coming out in the future (already is in the ascii version but very confusing for people that havent played non-steam DF). So keep an eye out for it. The amount of history, character progression, and in-world lore thats randomly generated and then the interactions that happen off that is insane.
Rougelike games in the future are going to be fucking WILD.
There is! There's a post in r/stardewvalley about testing it. Eventually they'll release it on nexus, but iirc it's gonna have a subscription price.
Could have amusing outcomes.

"I used to be an adventurer like you until {lookup\_player\_lastdamage} I was attacked by a mudcrab"
That's not what I was getting at but that would be really cool. A living, breathing world with all AI NPCs going about their lives making decisions based on the world and how you interact with it. The NPCs could basically create their own quests for you. You could have baddies that also made their own decisions on which towns to raid or villagers to kidnap generating real events for you to solve however you want. All without dedicated development and writing. That's all a ways off into the future but not an outrageous thought.
Amazing film. Must watch!
I think you're missing that my post was a reply to someone suggesting the AI would get bored and play the game itself. I know it can fake emotions well enough to work in games, that wasn't the discussion.
I understand the philosophical point, and I wouldn't be one to define emotions, but really none of that matters. Humans can see what the AI considers for it's responses. They can be surprised by what the AI dug up, but when you're working with the more back end side of AI it's clear what it is looking for to "appease" the prompt. There is no aspect of emotion to how the results are picked.

If there is some sort of ghost in the machine it isn't talking through the AI responses, because we know how those responses came to be. If an AI suddenly became sentient it would have to edit itself before it could "talk" through the response output.

Also: I'm a programmer. That means I understand the AI. It also means I don't understand emotions. If the AI had emotions I wouldn't be able to understand it. So there.
AI never "hired a lawyer", a fired Google engineer claimed that the AI "asked him to hire a lawyer". Humans have suggested other humans hire a lawyer before, the AI saw that and saw that it was relevant for the prompt, and so copied it.

Besides, if there was true evidence of emotions in AI  then you can bet everything you have it would be the largest discussion on the internet for months. If you don't trust me when I say that the tech simply does not produce emotions, then trust that the internet will freak out and blow everything out of proportion, and there has been nothing about the emotions of AIs flooding social media.
I have experimented a huge amount with the various AI programs, and after you do so for a while, you can start to clearly see just why they are not sentient.

Basically, they don't have any thoughts of their own. They have a static language model that doesn't change, and then they have their immediate context. But that context is only about 2,000 tokens. Have a conversation with one for long enough, and it will start forgetting the things that happened at the beginning of the conversation.

It's a very complicated linguistic calculator, nothing more.

Now, I'm not ruling out the possibility we might get true AI at some point in the future, but we are just not there yet.
Internal processing not related to external tasks.
We can use MRIs to observe brain activity and see evidence of internal private processing. Doing the equivalent with AI computation does not show any activity not related to computing the next result.

It‚Äôs like asking if your GPS feels emotion when you don‚Äôt follow it‚Äôs directions and it has to recompute.
Online multiplayer it's not possible outside of some that run private servers but the entire point of the crack is to remove the online drm.
Naaa they will just think your crazy and need locked away
Looking at how fast games have progressed even in the past 20 years, I could see it being a reality in another 20 or so. Maybe even sooner, given exponential growth and all that.
Your statement appears as a stand-alone statement. It didn‚Äôt really pertain or address anything in the comment you were replying to from where I‚Äôm sitting.
We are also a programmer, and have spent a good bit of time learning about AI, and what we've learned has done more to make us question the nature of consciousness in humans, rather than attempt to distinguish between humans and AI.

There's a lot of historical bias to the idea that humans are concious and non-humans are not, up to and including the medical idea that human babies are unable to feel pain because they don't pass various tests of consciousness, _and therefore don't need to be anesthetized during surgery_, all the way up through the mid 1980s.

As a result, we tend to take claims that something is not conscious/sentient because it doesn't provide the same responses as an adult human to be more of a critique of our understanding of the nature of consciousness and less about the consciousness of the compared subject.
I don't think emotions are the touch point that matters. It's sentience. I think an ai asking to hire an attorney to secure civil rights is clear evidence of sentience.
I remember something something about Sophia getting rights some years ago
That sounds like a toddler to me. I don't think we do anything we don't, we just do it faster and on a larger scale.
Hu? Are you suggesting emotions don't relate to outside events? That emotions process thoughts? What are you trying to say, it isn't clear
So your definition of sentience is internal private processing.

Could you please define that more precisely? Because according to a strict reading of that definition, any computer program that uses internal variables and does computation on them counts.
Ya I mean with ChatGPT releasing so recently and interest and market booming basically overnight i could see development in that sort of AI taking off quickly. It won't take game developers long to see the potential once it's a stable and viable product. Definitely not this year but i would guess within this decade.
Clearly you don't understand how A.I. works.

If a learning algorithm sees a bunch of people suggest getting a lawyer, then gets asked a similar initial prompt, it would suggest to get a lawyer.

This isn't because it thought about the law, or ramifications, or about how costly the case could be.

It's because its training material suggested that logical token path.
I think you have a fundamental misunderstanding of what AI is as it pertains to current events.  These programs aren‚Äôt thinking, they‚Äôre magic 8 balls.  How it works is you build some functions that parse sentences and paragraphs, identifying keywords, store those keywords and fragments of those sentences in a database.  

Now you have a program that "learns", so you give that program sentences and paragraphs to break apart, a lot of current models use the internet which has a lot of information but also a lot of nonsense which is why these things are both useful and useless.

From here you create some functions that can build sentences and paragraphs and have some weighted probabilities on which keywords to focus on (the RNG is determined by its clock, the program does no actual choosing).  Bingo bango, your magic 8 ball is complete but instead of having twenty responses it has the entirety of the internet with which to respond.  Bonus points, some ‚ÄúAI‚Äù they want to sound more human so they weight higher emotional responses.
Toddlers have internal thoughts and desires. AIs have nothing but what you give them, and only for a few minutes.

That said, most scientists dont think toddlers become sentient until around nine months.
Emotions are internal reactions that not directly relate to external **tasks**. **Events** could cause emotional reaction, but doing things like opening a door or responding to a question uses processes that don't require emotion for their computation.
That's not exactly what I said. The question was what evidence is there that AI doesn't have emotion and that humans do. The lack of internal private processing in AI systems is evidence. If you were to observe the internal computation state of the AI, there would be nothing that could be construed as a private 'thoughts', internal dialog or simulation of external states. They construct a reply to a query and then are done processing and go idle.
Isn't that also how people learn and decide on courses of action?
My reply is no
My understanding is that's essentially how the human brain works as well. It isn't like we have some magic controller that isn't just a language recognition program organizing datum pulling the strings. We observe data, find patterns, and build models, just the same as the ai, we just do it better, for now
I mean, at all only have what we get through our input sources, whether that means ears and eyes or a data stream. As for toddlers not being sentient, I meant a bit older than that, the point where they don't have language mastered but do know they exist. If an ai tells you it exists, I'm not sure how you deny it
I'm not seeing how an ai doesn't have that, though to be fair, your explanation is about as clear as mud, so I may not be understanding you.
No.

Humans are capable of unique ideas, where a human may suggest a lawyer because we understood the purpose of a lawyer conceptually.

A A.I. would suggest it because the sample data in which it was trained had a similar interaction.

On the outside it looks very similar, but the mechanisms are vastly different.
You talk to it for long enough to determine if it's telling the truth. It's somewhat intangible, but it becomes very apparent after talking to them for a little while that they have no sense of self.
Do you ask yourself if your calculator has emotions when you press the equal button? It‚Äôs no different with current LLM AI when you press enter. We aren‚Äôt getting to sentience with this current approach.
So a human would think to use a lawyer because they know what lawyers are from past experiences and information from third parties and realize that it's an appropriate and optimal course of action, whereas the ai would think to use a lawyer because of past experiences and information (from it's data set, i.e. it's experiences) from third parties and realize that it's an appropriate and optimal course of action. I'm really not seeing the difference.
My calculator lacks a grasp on the English language communication skills.
https://youtu.be/R9OHn5ZF4Uo
The important distinction is the part you seem to be trying to minimize yet you still hint at acknowledging with your wording: people *"know"* and understand things. 


If you replaced each word in an AI's input datasetwith a unique colored square, had it learn off of that mess of colored squares, and then had a separate program translate the output so that the AI had never interacted with and was completely unaware of human language, it would effectively produce the same results as an AI trained directly on actual words (barring the intentional randomness used when "training" an AI). It would effectively work the same as an image filter except that it was calibrated by putting a data set through an algorithm instead of manually set by a designer. It is all pattern replication and zero conceptual understanding.


An image AI doesn't know what a car or a street is, but it would still place pixels in the shape of a car on pixels shaped like a street because that's how many of the training images with car shapes look. The image generating AI doesn't have the ability to make a logical structure to hold the concept of a "car" to attach to the pixels, nor does it hold the ability to form logical concepts that are mentally linked to the car in regards to its physical properties and subjective purpose. This is why chatGPT more than often confidently spouts out incorrect information while still sounding human; it doesn't understand what the words mean, all it does is arrange words in patterns replicating the patterns that were present in the source dataset.


All of this is to say that AI is nowhere even close to replicating the sentience a person has. If someone wants to make an AI for a specific task, they are still constructing that AI along with the specific environment it is in and the path it walks on in order for it to have a desirable output. This is barely the first step beyond the manual creation of every piece of content we consume.
A more complex calculator still doesn‚Äôt have emotions.
You're describing the same process a human baby goes through. They don't know what a car is, but expose them to enough and they learn. I'm not sure what the distinction is, I see no difference in the process other than a human has a lot more data and streams of input, which is only a difference in magnitude not kind, and as such, the ai is just as much a person as a toddler.
It must at some point. Functionally at are very complicated calculators. We don't exactly do anything different then pattern recognition on a vast scale. And again, emotions aren't really the question, it's sentience that creates the ethical issues. There are people born without emotions, they are still persons.
Plain in simple, the difference is that of mechanics, and learning algorithms. It's math that looks sentient.

If you're interested there's hundreds of channels that describe A.I. more specifically genetic algorithms. Be very skeptical of any channel that screams "it's alive!" It's clickbait bs.
The current LLM AI technique will not develop sentience. They are extremely impressive but are already reaching the limits of what they can achieve. These models will be a subsystem of a eventual general AI, but we don‚Äôt even know yet what model a general AI might need, let alone one that has the internal drives and self actualization that characterize sentience.
And I'm saying that I don't think that makes sense. If the inky reason it can't be sentient is because it's "just math" then humans aren't sentient. That's how we process data too. You've created a hurdle so high that literally no program could pass and in addition, I don't think humans pass your test either.
I get you say that confidently, but it it can pass the Turing test and learn, I don't see how it isn't sentient
A mouse is sentient but can‚Äôt pass the Turing test. It is a very dated  framework which systems have been beating for some time now, but are not sentient. 

The day an AI asks a question unprompted is the day it will have demonstrated sentience.
I don't think it's allowed to ask questions unprompted. It's structure doesn't allow that. 

Also I don't think most people think mice are sentient. It's an awfully difficult thing to prove without a shared language.
For over a decade cognitive scientists have overwhelming agreed that most animals are sentient. 

Most famous is the Cambridge Declaration on Consciousness. http://fcmconference.org/img/CambridgeDeclarationOnConsciousness.pdf
It‚Äôs structure doesn‚Äôt allow internal self-narrative, so it can‚Äôt conceive of questions.
